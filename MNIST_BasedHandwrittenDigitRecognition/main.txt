#include <iostream>
#include <cmath>
#include <hls_math.h>

#define INPUT_SIZE 784  // 28 * 28
#define HIDDEN_SIZE 128
#define OUTPUT_SIZE 10

typedef float data_t;

data_t exp_approx(data_t x) {
    #pragma HLS inline
    // Use a simple approximation for exp(x), such as the Taylor series or a lookup table.
    // Here is an example of a simple approximation using a limited number of terms in the Taylor series:
    const int num_terms = 5;
    data_t result = 1.0;
    data_t term = 1.0;

    for (int i = 1; i < num_terms; ++i) {
        term *= x / i;
        result += term;
    }

    return result;
}

void relu(data_t input[HIDDEN_SIZE], data_t output[HIDDEN_SIZE]) {
    for (int i = 0; i < HIDDEN_SIZE; i++) {
        output[i] = input[i] > 0 ? input[i] : 0;
    }
}

void softmax(data_t input[OUTPUT_SIZE], data_t output[OUTPUT_SIZE]) {
    data_t max_val = input[0];
    for (int i = 1; i < OUTPUT_SIZE; i++) {
        if (input[i] > max_val) {
            max_val = input[i];
        }
    }

    data_t sum = 0;
    for (int i = 0; i < OUTPUT_SIZE; i++) {
        output[i] = exp_approx(input[i] - max_val);
        sum += output[i];
    }

    for (int i = 0; i < OUTPUT_SIZE; i++) {
        output[i] /= sum;
    }
}

void dense_1(data_t input[INPUT_SIZE], data_t output[HIDDEN_SIZE], const data_t weights[INPUT_SIZE][HIDDEN_SIZE], const data_t bias[HIDDEN_SIZE]) {

	for (int i = 0; i < HIDDEN_SIZE; i++) {

    	data_t sum = bias[i];
        for (int j = 0; j < INPUT_SIZE; j++) {
            sum += input[j] * weights[i][j];
        }
        output[i] = sum;
    }
}

void dense_2(data_t input[HIDDEN_SIZE], data_t output[OUTPUT_SIZE], const data_t weights[HIDDEN_SIZE][OUTPUT_SIZE], const data_t bias[OUTPUT_SIZE]) {
    for (int i = 0; i < OUTPUT_SIZE; i++) {
        data_t sum = bias[i];
        for (int j = 0; j < HIDDEN_SIZE; j++) {
            sum += input[j] * weights[i][j];
        }
        output[i] = sum;
    }
}

void neural_network(data_t input[INPUT_SIZE], data_t output[OUTPUT_SIZE],
                    const data_t dense_1_weights[INPUT_SIZE][HIDDEN_SIZE], const data_t dense_1_bias[HIDDEN_SIZE],
                    const data_t dense_2_weights[HIDDEN_SIZE][OUTPUT_SIZE], const data_t dense_2_bias[OUTPUT_SIZE]) {

    #pragma HLS INTERFACE m_axi port=input offset=slave bundle=gmem
    #pragma HLS INTERFACE m_axi port=output offset=slave bundle=gmem
    #pragma HLS INTERFACE m_axi port=dense_1_weights offset=slave bundle=gmem
    #pragma HLS INTERFACE m_axi port=dense_1_bias offset=slave bundle=gmem
    #pragma HLS INTERFACE m_axi port=dense_2_weights offset=slave bundle=gmem
    #pragma HLS INTERFACE m_axi port=dense_2_bias offset=slave bundle=gmem
    #pragma HLS INTERFACE s_axilite port=return bundle=control

    data_t dense_1_out[HIDDEN_SIZE];
    data_t relu_out[HIDDEN_SIZE];
    data_t dense_2_out[OUTPUT_SIZE];

    // Layer 1: Dense
    dense_1(input, dense_1_out, dense_1_weights, dense_1_bias);

    // Layer 1: ReLU Activation
    relu(dense_1_out, relu_out);

    // Layer 2: Dense
    dense_2(relu_out, dense_2_out, dense_2_weights, dense_2_bias);

    // Layer 2: Softmax Activation
    softmax(dense_2_out, output);
}
